#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ•°æ®é›†åŠ è½½è„šæœ¬
ç”¨äºéªŒè¯opus100è‹±ä¸­æ•°æ®é›†çš„åŠ è½½å’Œæ ¼å¼
"""

import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

from datasets import load_dataset
import torch
from config import get_config

def test_dataset_loading():
    """æµ‹è¯•æ•°æ®é›†åŠ è½½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•opus100è‹±è¯‘æ±‰æ•°æ®é›†åŠ è½½...")
    config = get_config()

    try:
        # åŠ è½½æ•°æ®é›† - ç°åœ¨æ˜¯en-zhæ–¹å‘
        print("ğŸ“¥ æ­£åœ¨åŠ è½½opus100 en-zhæ•°æ®é›†...")
        ds_full = load_dataset("opus100", "en-zh")

        print("âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ!")
        print(f"æ•°æ®é›†åŒ…å«çš„å­é›†: {list(ds_full.keys())}")
        print(f"è®­ç»ƒé›†å¤§å°: {len(ds_full['train'])} samples")
        print(f"éªŒè¯é›†å¤§å°: {len(ds_full['validation'])} samples")
        print(f"æµ‹è¯•é›†å¤§å°: {len(ds_full['test'])} samples")

        # æ£€æŸ¥æ•°æ®æ ¼å¼
        print("\nğŸ” æ£€æŸ¥æ•°æ®æ ¼å¼:")
        train_sample = ds_full['train'][0]
        print(f"ç¬¬ä¸€æ¡è®­ç»ƒæ•°æ®: {train_sample}")

        # éªŒè¯ç¿»è¯‘å­—æ®µ
        if 'translation' in train_sample:
            translation = train_sample['translation']
            print(f"\nç¿»è¯‘å­—æ®µå†…å®¹:")
            print(f"  è‹±æ–‡å­—æ®µå­˜åœ¨: {'en' in translation}")
            print(f"  ä¸­æ–‡å­—æ®µå­˜åœ¨: {'zh' in translation}")

            if 'en' in translation and 'zh' in translation:
                print(f"\nğŸ“„ æ ·æœ¬ç¤ºä¾‹:")
                print(f"  è‹±æ–‡: {translation['en']}")
                print(f"  ä¸­æ–‡: {translation['zh']}")

                # æ£€æŸ¥å­—ç¬¦é•¿åº¦
                en_len = len(translation['en'])
                zh_len = len(translation['zh'])
                print(f"\nğŸ“ é•¿åº¦å¯¹æ¯”:")
                print(f"  è‹±æ–‡é•¿åº¦: {en_len} å­—ç¬¦")
                print(f"  ä¸­æ–‡é•¿åº¦: {zh_len} å­—ç¬¦")
                print(f"  è‹±ä¸­é•¿åº¦æ¯”: {en_len/zh_len:.2f}")

        # æ£€æŸ¥å‡ æ¡éšæœºæ ·æœ¬
        print(f"\nğŸ¯ æ›´å¤šéšæœºæ ·æœ¬ (è‹±æ–‡â†’ä¸­æ–‡):")
        for i in range(3):
            sample = ds_full['train'][i]
            en_text = sample['translation']['en']
            zh_text = sample['translation']['zh']
            print(f"  æ ·æœ¬{i+1}: '{en_text[:50]}...' -> '{zh_text[:50]}...'")

        print(f"\nğŸ”§ é…ç½®éªŒè¯:")
        print(f"  æºè¯­è¨€: {config['lang_src']}")
        print(f"  ç›®æ ‡è¯­è¨€: {config['lang_tgt']}")
        print(f"  æ•°æ®æ–¹å‘: {config['datasource']} en-zh")

        print("\nâœ¨ æ•°æ®é›†æµ‹è¯•å®Œæˆï¼æ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥å¼€å§‹è‹±è¯‘æ±‰è®­ç»ƒã€‚")
        return True

    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    test_dataset_loading()